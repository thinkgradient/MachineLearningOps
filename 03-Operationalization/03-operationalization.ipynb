{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Lab 3 - Model Deplyoment \n",
    "\n",
    "In this lab, you will learn how to use Azure Machine Learning Service to deploy, manage, and monitor the trained models.\n",
    "\n",
    "\n",
    "The following diagram illustrates the complete deployment workflow.\n",
    "\n",
    "![AML Arch](https://github.com/jakazmie/images-for-hands-on-labs/raw/master/model-ci-cd.png)\n",
    "\n",
    "\n",
    "\n",
    "The deployment workflow includes the following steps:\n",
    "\n",
    "- Create/Retrain the model\n",
    "- Register the model in a registry hosted in your Azure Machine Learning Service workspace\n",
    "- Register an image that pairs a model with a scoring script and dependencies in a portable container\n",
    "- Deploy the image as a web service in the cloud or to edge devices\n",
    "- Monitor and collect data\n",
    "\n",
    "\n",
    "You completed the first two steps in the previous labs.\n",
    "\n",
    "In this lab we will walk-through the reminder of the deployment workflow.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to the workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK Version: 1.0.23\n"
     ]
    }
   ],
   "source": [
    "# Verify AML SDK Installed\n",
    "# view version history at https://pypi.org/project/azureml-sdk/#history \n",
    "import azureml.core\n",
    "print(\"SDK Version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Falling back to use azure cli login credentials.\n",
      "If you run your code in unattended mode, i.e., where you can't give a user input, then we recommend to use ServicePrincipalAuthentication or MsiAuthentication.\n",
      "Please refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the config file in: /home/byteb/events/MachineLearningOps/.azureml/config.json\n",
      "MLOpsFatosIsmali\n",
      "DSIMLOpsHack\n",
      "westeurope\n",
      "051aa254-957d-4431-a6df-6caa8963bdd7\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "# Read the workspace config from file\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and deploy the container image encapsulating the model\n",
    "\n",
    "When you deploy a model using AML to either ACI or AKS, you are deploying a Docker container encapsulating a trained model, its dependencies, and a web services wrapper around the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create scoring script\n",
    "Create the scoring script, called score.py, used by the web service call to invoke the model.\n",
    "\n",
    "You must include two required functions in the scoring script:\n",
    "\n",
    "- The `init()` function, which loads the model into a global object. This function is run only once when the Docker container is started.\n",
    "\n",
    "- The `run(input_data)` function uses the model to predict a value based on the input data. Inputs and outputs to the run typically use JSON for serialization and de-serialization, but other formats can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile score.py\n",
    "\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from azureml.core.model import Model\n",
    "from azureml.core import Workspace\n",
    "\n",
    "def init():\n",
    "    try:\n",
    "        global model   \n",
    "\n",
    "        model_name = '<<modelid>>'\n",
    "        model_path = Model.get_model_path(model_name)\n",
    "        model = joblib.load(model_path)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print('Exception during init: ', str(e))\n",
    "\n",
    "def run(input_json):     \n",
    "    try:\n",
    "        inputs = json.loads(input_json)\n",
    "        prediction = model.predict(inputs)\n",
    "        prediction = json.dumps(prediction.tolist())\n",
    "\n",
    "    except Exception as e:\n",
    "        prediction = str(e)\n",
    "    return prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Substitute the actual model ID in the script file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import Model\n",
    "\n",
    "model_name = 'propensity_to_buy_predictor'\n",
    "model = Model(ws, name=model_name)\n",
    "script_file_name = 'score.py'\n",
    "\n",
    "with open(script_file_name, 'r') as cefr:\n",
    "    content = cefr.read()\n",
    "    \n",
    "with open(script_file_name, 'w') as cefw:\n",
    "    cefw.write(content.replace('<<modelid>>', model.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review the updated script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "import json\n",
      "import os\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.externals import joblib\n",
      "\n",
      "from azureml.core.model import Model\n",
      "from azureml.core import Workspace\n",
      "\n",
      "def init():\n",
      "    try:\n",
      "        global model   \n",
      "\n",
      "        model_name = 'propensity_to_buy_predictor'\n",
      "        model_path = Model.get_model_path(model_name)\n",
      "        model = joblib.load(model_path)\n",
      "        \n",
      "    except Exception as e:\n",
      "        print('Exception during init: ', str(e))\n",
      "\n",
      "def run(input_json):     \n",
      "    try:\n",
      "        inputs = json.loads(input_json)\n",
      "        prediction = model.predict(inputs)\n",
      "        prediction = json.dumps(prediction.tolist())\n",
      "\n",
      "    except Exception as e:\n",
      "        prediction = str(e)\n",
      "    return prediction\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"score.py\",\"r\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Conda dependencies environment file.\n",
    "\n",
    "Next, create an environment file that specifies the script's package dependencies. This file is used to ensure that all of those dependencies are installed in the Docker image. \n",
    "\n",
    "\n",
    "You need to replace the values in `experiment_name`  with the name of your experiment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies \n",
    "\n",
    "mycondaenv = CondaDependencies.create(conda_packages=['scikit-learn','numpy','pandas'])\n",
    "\n",
    "with open(\"mydeployenv.yml\",\"w\") as f:\n",
    "    f.write(mycondaenv.serialize_to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review the content of 'yml' file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Conda environment specification. The dependencies defined in this file will\n",
      "# be automatically provisioned for runs with userManagedDependencies=False.\n",
      "\n",
      "# Details about the Conda environment file format:\n",
      "# https://conda.io/docs/user-guide/tasks/manage-environments.html#create-env-file-manually\n",
      "\n",
      "name: project_environment\n",
      "dependencies:\n",
      "  # The python interpreter version.\n",
      "  # Currently Azure ML only supports 3.5.2 and later.\n",
      "- python=3.6.2\n",
      "\n",
      "- pip:\n",
      "  - azureml-defaults==1.0.23.*\n",
      "- scikit-learn\n",
      "- numpy\n",
      "- pandas\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"mydeployenv.yml\",\"r\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create docker image for deployment\n",
    "\n",
    "To create a Container Image, you need four things: the model metadata (as retrieved from Model Registry), the scoring script file, the runtime configuration (defining whether Python or PySpark should be used) and the Conda Dependencies file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating image\n",
      "Running....................................................................\n",
      "SucceededImage creation operation finished for image propensity-to-buy-classifier:1, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.image import ContainerImage, Image\n",
    "\n",
    "# Define runtime\n",
    "runtime = \"python\" \n",
    "\n",
    "# Define scoring script\n",
    "driver_file = \"score.py\"\n",
    "\n",
    "# Define conda dependencies\n",
    "conda_file = \"mydeployenv.yml\"\n",
    "\n",
    "# configure the image\n",
    "image_config = ContainerImage.image_configuration(execution_script=driver_file, \n",
    "                                                  runtime=runtime, \n",
    "                                                  conda_file=conda_file,\n",
    "                                                  description=\"Image for propensity to buy predictor\",\n",
    "                                                  tags={\"Classifier\": \"AutomatedML\"})\n",
    "\n",
    "image = Image.create(name = \"propensity-to-buy-classifier\",\n",
    "                     models = [model],\n",
    "                     image_config = image_config, \n",
    "                     workspace = ws)\n",
    "\n",
    "image.wait_for_creation(show_output = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Download the Docker image from AML service\n",
    "\n",
    "You can download the docker image that gets deployed to the Azure container registry to your local docker environment. You need to have Docker installed in your local environment to be able to run the following commands. You also need to install the azure cli. https://docs.microsoft.com/en-us/cli/azure/install-azure-cli?view=azure-cli-latest\n",
    "\n",
    "To download (or pull) the docker image from the Azure container registry to your local docker registry run the following code from a terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az acr login --name <registry_name>\n",
    "docker pull (image_name:tag>\n",
    "            - pulls it locally to your docker registry\n",
    "docker images\n",
    "             - lists the docker image you just pulled locally\n",
    "docker run -i -t <image_name:tag> /bin/sh \n",
    "             - logs into the shell of the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the container image to ACI\n",
    "\n",
    "With the Container Image  in hand, you are almost ready to deploy to ACI. The next step is to define the size of the VM that ACI will use to run your Container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice, Webservice\n",
    "\n",
    "aci_config = AciWebservice.deploy_configuration(\n",
    "    cpu_cores = 1, \n",
    "    memory_gb = 1, \n",
    "    tags = {'name':'Azure ML ACI'}, \n",
    "    description = 'This is a deployment of the propensity to buy predictor.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point you can deploy the image to the webservice to ACI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying:  propensity-to-buy-predictor-aci\n",
      "Creating service\n",
      "Running........................\n",
      "SucceededACI service creation operation finished, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.webservice import Webservice\n",
    "\n",
    "service_name = \"propensity-to-buy-predictor-aci\"\n",
    "print(\"Deploying: \", service_name)\n",
    "aci_service = Webservice.deploy_from_image(deployment_config = aci_config,\n",
    "                                           image = image,\n",
    "                                           name = service_name,\n",
    "                                           workspace = ws)\n",
    "aci_service.wait_for_deployment(True)\n",
    "\n",
    "#print(aci_service.get_logs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the service\n",
    "\n",
    "Once the webservice deployment completes, you can use the returned webservice object to invoke the webservice. \n",
    "\n",
    "#### Load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load a test dataset\n",
    "folder = '../datasets'\n",
    "filename = 'banking_test.csv'\n",
    "pathname = os.path.join(folder, filename)\n",
    "df_test = pd.read_csv(pathname, delimiter=',')\n",
    "feature_columns = [\n",
    "                   # Demographic\n",
    "                   'age', \n",
    "                   'job', \n",
    "                   'education', \n",
    "                   'marital',  \n",
    "                   'housing', \n",
    "                   'loan', \n",
    "                   # Previous campaigns\n",
    "                   'month',\n",
    "                   'campaign',\n",
    "                   'poutcome',\n",
    "                   # Economic indicators\n",
    "                   'emp_var_rate',\n",
    "                   'cons_price_idx',\n",
    "                   'cons_conf_idx',\n",
    "                   'euribor3m',\n",
    "                   'nr_employed']\n",
    "df_test = df_test[feature_columns]\n",
    "df_test = pd.get_dummies(df_test, drop_first=True).astype(dtype='float')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Invoke the service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[49.0, 2.0, -0.1, 93.2, -42.0, 4.0760000000000005, 5195.8, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0], [52.0, 3.0, 1.4, 93.918, -42.7, 4.962, 5228.1, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0], [72.0, 1.0, -2.9, 92.201, -31.4, 0.884, 5076.2, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0], [26.0, 7.0, -1.7, 94.215, -40.3, 0.8220000000000001, 4991.6, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0], [38.0, 1.0, -0.1, 93.2, -42.0, 4.021, 5195.8, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0], [47.0, 2.0, 1.1, 93.994, -36.4, 4.855, 5191.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0], [46.0, 2.0, 1.4, 93.918, -42.7, 4.962, 5228.1, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0], [23.0, 6.0, -2.9, 92.469, -33.6, 0.908, 5076.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0], [45.0, 1.0, 1.4, 93.918, -42.7, 4.959, 5228.1, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0], [44.0, 1.0, -1.8, 92.893, -46.2, 1.3130000000000002, 5099.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]]\n",
      "Result:\n",
      "[0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "test_data = json.dumps(df_test[0:10].values.tolist())\n",
    "print(test_data)\n",
    "result = aci_service.run(input_data = test_data)\n",
    "print(\"Result:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aci_service.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the container image to AKS\n",
    "\n",
    "Once you are familiar with the process for deploying a webservice to ACI, you will find the process for deploying to AKS to be similar with one additional step that creates the AKS cluster first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provision an AKS cluster \n",
    "\n",
    "from azureml.core.compute import AksCompute, ComputeTarget\n",
    "from azureml.core.webservice import Webservice, AksWebservice\n",
    "\n",
    "# Use the default configuration, overriding the default location to a known region that supports AKS\n",
    "prov_config = AksCompute.provisioning_configuration(location='westus2')\n",
    "\n",
    "aks_name = 'aks-cluster01' \n",
    "\n",
    "# Create the cluster\n",
    "aks_target = ComputeTarget.create(workspace = ws, \n",
    "                                  name = aks_name, \n",
    "                                  provisioning_configuration = prov_config)\n",
    "\n",
    "\n",
    "# Wait for cluster to be ready\n",
    "aks_target.wait_for_completion(show_output = True)\n",
    "print(aks_target.provisioning_state)\n",
    "print(aks_target.provisioning_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With your AKS cluster ready, now you can deploy your webservice. Once again, you need to provide a configuration for the size of resources allocated from the AKS cluster to run instances of your Container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.image import ContainerImage, Image\n",
    "\n",
    "images = Image.list(ws, image_name=\"propensity-to-buy-classifier\")\n",
    "images\n",
    "image = images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the web service configuration (using defaults)\n",
    "aks_config = AksWebservice.deploy_configuration()\n",
    "\n",
    "aks_service_name ='propensity-to-buy-predictor-aks'\n",
    "\n",
    "aks_service = Webservice.deploy_from_image(\n",
    "  workspace=ws, \n",
    "  name=aks_service_name, \n",
    "  image = image,\n",
    "  deployment_target=aks_target\n",
    "  )\n",
    "\n",
    "\n",
    "aks_service.wait_for_deployment(show_output = True)\n",
    "print(aks_service.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the service\n",
    "As before, you can use the webservice object returned by the deploy_from_model method to invoke your deployed webservice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "test_data = json.dumps(df_test[0:10].values.tolist())\n",
    "result = aks_service.run(input_data = test_data)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up\n",
    "\n",
    "Make sure to remove ACI and AKS deployments. Use Azure Portal to remove *Deployments* and *AKS Compute*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
